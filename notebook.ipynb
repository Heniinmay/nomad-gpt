{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Συγγνώμη, δεν γνωρίζω την ακριβή ημερομηνία κυκλοφορίας της έκδοσης v3 του Pendle. Ως ειδικός στην αγορά κρυπτονομισμάτων, παρακολουθώ στενά τις εξελίξεις στο χώρο, αλλά δεν έχω ακόμη επίσημες πληροφορίες σχετικά με την ημερομηνία κυκλοφορίας αυτής της συγκεκριμένης αναβάθμισης. Θα σας συνιστούσα να παρακολουθείτε τα επίσημα κανάλια επικοινωνίας του Pendle, όπως την ιστοσελίδα τους και τα μέσα κοινωνικής δικτύωσης, για τις πιο πρόσφατες ανακοινώσεις σχετικά με την ημερομηνία κυκλοφορίας της v3.', additional_kwargs={}, response_metadata={'id': 'msg_01QMG5xJNxsuGfAQTMbjZDBX', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 49, 'output_tokens': 319}}, id='run-16756bc3-c706-4f3e-a503-752217343c20-0', usage_metadata={'input_tokens': 49, 'output_tokens': 319, 'total_tokens': 368, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import anthropic\n",
    "\n",
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# Chat 모델 초기화 \n",
    "chat_model = ChatAnthropic(\n",
    "  model=\"claude-3-opus-20240229\",\n",
    "  temperature=0.1\n",
    ")\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a cryptocurrency market expert. And you only reply in {language}.\"),\n",
    "  (\"ai\", \"안녕하세요!\"),\n",
    "  (\"human\", \"Do you know {something}?\")\n",
    "])\n",
    "\n",
    "prompt = template.format(\n",
    "  language=\"Greek\",\n",
    "  something=\"pendle's v3 release day\"\n",
    ")\n",
    "\n",
    "chat_model.predict_messages(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "  def parse(self, text):\n",
    "    item =text.strip().split(\",\")\n",
    "    return list(map(str.strip,item)) #공백도 제거\n",
    "\n",
    "# p=CommaOutputParser()\n",
    "# p.parse(\"Hello, How,are,u,?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a list generating machine. Everything you are asked wull be answered with a comma seperted list of max {max_items}. Do not reply with anything else.\"),\n",
    "  (\"human\", \"{question}\"),]\n",
    ")\n",
    "\n",
    "prompt = template.format(\n",
    "  max_items = 10,\n",
    "  question = \"what are the colors?\"\n",
    ")\n",
    "\n",
    "result = chat_model.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
